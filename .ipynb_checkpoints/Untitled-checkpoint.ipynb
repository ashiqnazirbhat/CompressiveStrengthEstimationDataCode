{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2c81d86-9f94-40c3-8330-57af9b0cdb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98fcdc57-85da-42d1-8592-bf33553d57d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_generator(latent_dim, data_dim):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(latent_dim,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(data_dim, activation=None)  # Output layer for regression (no activation)\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d074e686-481f-4795-ad6d-ef221fdf13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(data_dim):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(data_dim,)),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation=None)  # Single output value (real or fake)\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2be61815-ecdc-4c31-9bd3-65d36e86c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bfcaaba-27b5-4d8b-a516-0880fe783c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "# Wasserstein loss function\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e4f25ad-60df-407c-a35e-f1bcfd612260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile the discriminator\n",
    "discriminator.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "# Compile the GAN (stacking the generator and discriminator)\n",
    "gan.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94b4d03d-e3c0-4771-9bcd-c2a6887faf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Wasserstein loss function\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10dca2cf-42c3-49ea-b637-774ae0f2d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Compile the discriminator\n",
    "discriminator.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss=wasserstein_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39fcee98-013f-476f-89db-1133c298c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the GAN (stacking the generator and discriminator)\n",
    "gan.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss=wasserstein_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2b00f20-a3c6-4acb-a264-61815becd789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_wgan(generator, discriminator, gan, real_data, latent_dim, epochs, batch_size, n_critic):\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(n_critic):  # Train discriminator multiple times per generator update\n",
    "            # Train the discriminator on real data\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "            real_samples = real_data[np.random.randint(0, real_data.shape[0], batch_size)]\n",
    "            fake_samples = generator.predict(noise)\n",
    "            \n",
    "            # Train on real and fake samples with Wasserstein loss\n",
    "            d_loss_real = discriminator.train_on_batch(real_samples, -np.ones((batch_size, 1)))  # Real class is -1\n",
    "            d_loss_fake = discriminator.train_on_batch(fake_samples, np.ones((batch_size, 1)))   # Fake class is 1\n",
    "\n",
    "        # Train the generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        g_loss = gan.train_on_batch(noise, -np.ones((batch_size, 1)))  # Generator tries to fool the discriminator (label: -1)\n",
    "\n",
    "        # Print the progress\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs} - D Loss: {d_loss_real + d_loss_fake:.4f}, G Loss: {g_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d53e75d-8fea-48b9-90ab-306fb08fa0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define latent dimension\n",
    "latent_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b62afa8a-d204-4916-ba0e-3d668621f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dummy real dataset (replace with actual dataset)\n",
    "real_data = np.random.rand(1000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "180a89a6-07a6-431a-ba0b-d3042467d99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.79237107e-01],\n",
       "       [8.47683336e-01],\n",
       "       [6.47353885e-01],\n",
       "       [6.81507309e-01],\n",
       "       [6.04652398e-01],\n",
       "       [4.84271666e-02],\n",
       "       [2.10232020e-01],\n",
       "       [8.74177773e-01],\n",
       "       [2.61930066e-01],\n",
       "       [9.56537240e-01],\n",
       "       [7.54120148e-01],\n",
       "       [9.43640080e-01],\n",
       "       [9.77064034e-01],\n",
       "       [7.42147289e-01],\n",
       "       [1.73912453e-01],\n",
       "       [5.78578424e-01],\n",
       "       [9.15624848e-01],\n",
       "       [2.31161011e-01],\n",
       "       [3.82953009e-01],\n",
       "       [6.15761648e-01],\n",
       "       [8.08369868e-01],\n",
       "       [2.01689189e-01],\n",
       "       [2.03103973e-01],\n",
       "       [6.93380655e-01],\n",
       "       [9.35592302e-01],\n",
       "       [1.34129412e-01],\n",
       "       [9.61137204e-01],\n",
       "       [1.95258803e-01],\n",
       "       [8.78796627e-01],\n",
       "       [1.70047401e-01],\n",
       "       [4.58115268e-01],\n",
       "       [6.64102324e-01],\n",
       "       [9.94590817e-02],\n",
       "       [6.10087600e-01],\n",
       "       [9.14920091e-01],\n",
       "       [7.75220314e-01],\n",
       "       [6.89479058e-01],\n",
       "       [4.84990375e-02],\n",
       "       [4.95479395e-01],\n",
       "       [9.35060003e-01],\n",
       "       [1.43811670e-01],\n",
       "       [6.07211128e-01],\n",
       "       [3.98749632e-01],\n",
       "       [1.50759540e-01],\n",
       "       [6.47481186e-01],\n",
       "       [8.57038857e-01],\n",
       "       [5.09978601e-01],\n",
       "       [3.67686715e-01],\n",
       "       [3.00357823e-01],\n",
       "       [4.76007239e-01],\n",
       "       [8.54934143e-01],\n",
       "       [4.90041919e-01],\n",
       "       [5.30563599e-01],\n",
       "       [3.43657394e-01],\n",
       "       [8.26043692e-01],\n",
       "       [6.74470701e-01],\n",
       "       [5.86398028e-01],\n",
       "       [2.61946081e-01],\n",
       "       [1.94366912e-01],\n",
       "       [3.25379236e-01],\n",
       "       [9.84830991e-01],\n",
       "       [7.55196943e-01],\n",
       "       [5.16653153e-01],\n",
       "       [7.70838717e-01],\n",
       "       [9.32257912e-01],\n",
       "       [1.10018265e-01],\n",
       "       [8.38693477e-01],\n",
       "       [7.17845980e-01],\n",
       "       [7.87204727e-01],\n",
       "       [2.72631868e-01],\n",
       "       [1.89981394e-01],\n",
       "       [6.48114515e-01],\n",
       "       [2.55764447e-01],\n",
       "       [4.71473520e-01],\n",
       "       [1.33345039e-01],\n",
       "       [3.87867762e-02],\n",
       "       [6.16008488e-01],\n",
       "       [2.40810506e-01],\n",
       "       [2.70693186e-01],\n",
       "       [7.76967026e-01],\n",
       "       [8.73221819e-01],\n",
       "       [8.19692673e-01],\n",
       "       [5.96357016e-01],\n",
       "       [4.48261601e-02],\n",
       "       [6.93357504e-01],\n",
       "       [9.85565842e-01],\n",
       "       [4.61306086e-01],\n",
       "       [9.50449711e-03],\n",
       "       [3.94658823e-01],\n",
       "       [8.24093641e-01],\n",
       "       [2.36830977e-01],\n",
       "       [1.62877318e-01],\n",
       "       [7.69009650e-01],\n",
       "       [6.89808342e-02],\n",
       "       [2.51444520e-01],\n",
       "       [4.33715053e-01],\n",
       "       [5.30972087e-01],\n",
       "       [6.17589471e-01],\n",
       "       [7.19781089e-01],\n",
       "       [9.10508499e-01],\n",
       "       [5.82061431e-01],\n",
       "       [7.58592463e-01],\n",
       "       [6.19796062e-01],\n",
       "       [8.09586971e-01],\n",
       "       [1.77925366e-01],\n",
       "       [9.89583309e-01],\n",
       "       [8.55208855e-02],\n",
       "       [6.86850980e-01],\n",
       "       [7.20827886e-01],\n",
       "       [2.88521149e-01],\n",
       "       [7.76013064e-01],\n",
       "       [3.32520813e-01],\n",
       "       [6.13262690e-01],\n",
       "       [4.30236261e-01],\n",
       "       [3.61177093e-01],\n",
       "       [6.57672379e-01],\n",
       "       [5.71025223e-01],\n",
       "       [1.18407943e-01],\n",
       "       [8.31466333e-01],\n",
       "       [9.26665002e-01],\n",
       "       [3.94713420e-01],\n",
       "       [4.27913418e-01],\n",
       "       [1.85096869e-01],\n",
       "       [4.46583611e-01],\n",
       "       [3.55654611e-01],\n",
       "       [7.23989492e-01],\n",
       "       [1.19847552e-01],\n",
       "       [8.10927210e-01],\n",
       "       [7.74875334e-01],\n",
       "       [1.19142728e-01],\n",
       "       [6.44265082e-01],\n",
       "       [4.91558214e-01],\n",
       "       [3.22995205e-01],\n",
       "       [2.61121906e-01],\n",
       "       [8.06582009e-01],\n",
       "       [3.84638833e-01],\n",
       "       [7.32035108e-01],\n",
       "       [9.44169544e-01],\n",
       "       [8.93058122e-01],\n",
       "       [1.21961164e-01],\n",
       "       [4.43722471e-01],\n",
       "       [3.27117913e-01],\n",
       "       [6.44610789e-01],\n",
       "       [3.99158955e-01],\n",
       "       [8.73291993e-01],\n",
       "       [3.35821226e-01],\n",
       "       [2.95673479e-01],\n",
       "       [5.21005214e-01],\n",
       "       [4.10689800e-01],\n",
       "       [3.31742784e-01],\n",
       "       [2.11686541e-01],\n",
       "       [1.00005730e-01],\n",
       "       [6.02565306e-01],\n",
       "       [9.28366850e-01],\n",
       "       [2.55537789e-01],\n",
       "       [6.34267324e-01],\n",
       "       [1.36796496e-01],\n",
       "       [2.87603516e-01],\n",
       "       [7.00556209e-01],\n",
       "       [3.36417135e-01],\n",
       "       [7.25478491e-01],\n",
       "       [6.03953158e-01],\n",
       "       [6.68093598e-01],\n",
       "       [7.09836595e-01],\n",
       "       [7.75734738e-01],\n",
       "       [9.09236876e-01],\n",
       "       [2.15316346e-01],\n",
       "       [1.54333001e-01],\n",
       "       [7.42514229e-01],\n",
       "       [3.34213245e-01],\n",
       "       [9.14937443e-01],\n",
       "       [5.40992811e-02],\n",
       "       [1.90580112e-01],\n",
       "       [8.92515228e-01],\n",
       "       [4.24321332e-01],\n",
       "       [9.16931148e-01],\n",
       "       [7.25563586e-01],\n",
       "       [6.83611481e-01],\n",
       "       [3.29429323e-02],\n",
       "       [4.99755164e-01],\n",
       "       [5.60227955e-01],\n",
       "       [6.10685601e-01],\n",
       "       [8.95655028e-01],\n",
       "       [3.76923611e-01],\n",
       "       [8.20520464e-01],\n",
       "       [2.67868998e-01],\n",
       "       [1.98278191e-01],\n",
       "       [1.20600367e-01],\n",
       "       [8.99543790e-01],\n",
       "       [1.29530960e-01],\n",
       "       [5.31028096e-01],\n",
       "       [4.20710741e-01],\n",
       "       [2.49168536e-01],\n",
       "       [3.94704678e-01],\n",
       "       [9.07903333e-01],\n",
       "       [3.92013975e-01],\n",
       "       [7.54581424e-02],\n",
       "       [4.97452692e-01],\n",
       "       [9.62697121e-02],\n",
       "       [3.60760230e-01],\n",
       "       [4.68133899e-02],\n",
       "       [9.95316417e-01],\n",
       "       [9.75843820e-01],\n",
       "       [9.32368740e-01],\n",
       "       [3.42772060e-01],\n",
       "       [1.84545714e-01],\n",
       "       [3.36823596e-01],\n",
       "       [2.54515102e-01],\n",
       "       [9.93458254e-01],\n",
       "       [9.45774627e-01],\n",
       "       [2.28765722e-01],\n",
       "       [2.18767691e-02],\n",
       "       [3.85386272e-01],\n",
       "       [3.44721347e-01],\n",
       "       [2.14510620e-01],\n",
       "       [3.63589892e-01],\n",
       "       [9.51907600e-01],\n",
       "       [6.29388715e-01],\n",
       "       [7.67410407e-01],\n",
       "       [7.81386532e-01],\n",
       "       [9.48450888e-01],\n",
       "       [6.57622518e-01],\n",
       "       [2.81549702e-01],\n",
       "       [7.75591813e-01],\n",
       "       [1.18001753e-01],\n",
       "       [9.68585256e-01],\n",
       "       [3.69203988e-01],\n",
       "       [5.55579125e-01],\n",
       "       [5.17552588e-01],\n",
       "       [4.24176346e-02],\n",
       "       [5.20807903e-01],\n",
       "       [4.01665338e-02],\n",
       "       [1.16409789e-01],\n",
       "       [9.75135067e-01],\n",
       "       [7.50794013e-01],\n",
       "       [7.46160211e-01],\n",
       "       [7.73603075e-01],\n",
       "       [5.78817387e-01],\n",
       "       [1.54725233e-01],\n",
       "       [2.58578594e-01],\n",
       "       [4.15350478e-01],\n",
       "       [2.14838024e-01],\n",
       "       [4.51128767e-01],\n",
       "       [9.97550455e-01],\n",
       "       [4.97709086e-02],\n",
       "       [4.06224057e-01],\n",
       "       [8.42501805e-01],\n",
       "       [3.22628355e-01],\n",
       "       [7.93473295e-01],\n",
       "       [5.17430714e-01],\n",
       "       [6.52340942e-01],\n",
       "       [5.29293043e-01],\n",
       "       [3.42528203e-01],\n",
       "       [9.65337847e-01],\n",
       "       [2.08008918e-01],\n",
       "       [6.97974188e-01],\n",
       "       [8.15785552e-01],\n",
       "       [9.17554798e-01],\n",
       "       [6.75705754e-01],\n",
       "       [5.25810899e-01],\n",
       "       [9.72908042e-02],\n",
       "       [7.53727342e-02],\n",
       "       [8.17063901e-01],\n",
       "       [6.53659693e-01],\n",
       "       [8.66951576e-01],\n",
       "       [7.89316029e-01],\n",
       "       [4.60295422e-01],\n",
       "       [8.23693506e-01],\n",
       "       [7.11510371e-01],\n",
       "       [2.19446365e-02],\n",
       "       [3.26784743e-01],\n",
       "       [3.62023798e-01],\n",
       "       [6.70179683e-01],\n",
       "       [1.60728698e-01],\n",
       "       [4.05654297e-01],\n",
       "       [2.01663423e-01],\n",
       "       [7.40460125e-01],\n",
       "       [9.93931047e-01],\n",
       "       [2.79051139e-01],\n",
       "       [7.46393083e-01],\n",
       "       [5.88376039e-01],\n",
       "       [2.58309014e-01],\n",
       "       [7.69746147e-01],\n",
       "       [1.42532028e-01],\n",
       "       [6.83769469e-01],\n",
       "       [2.71344530e-02],\n",
       "       [7.72047731e-01],\n",
       "       [5.63391440e-01],\n",
       "       [5.61884740e-01],\n",
       "       [3.88224559e-01],\n",
       "       [7.81650237e-01],\n",
       "       [2.96934600e-01],\n",
       "       [2.38059673e-01],\n",
       "       [3.81750679e-01],\n",
       "       [9.85533037e-01],\n",
       "       [6.20631456e-02],\n",
       "       [4.62732088e-01],\n",
       "       [2.49720265e-01],\n",
       "       [3.14280084e-01],\n",
       "       [3.83595163e-01],\n",
       "       [2.28465211e-01],\n",
       "       [6.79316466e-01],\n",
       "       [8.51112772e-01],\n",
       "       [8.85665039e-01],\n",
       "       [1.81040776e-01],\n",
       "       [8.02947492e-01],\n",
       "       [3.76778788e-01],\n",
       "       [8.69725466e-02],\n",
       "       [4.13572773e-01],\n",
       "       [5.75823650e-01],\n",
       "       [2.90950643e-01],\n",
       "       [6.87397946e-01],\n",
       "       [9.38944382e-02],\n",
       "       [6.00463069e-01],\n",
       "       [7.62261309e-01],\n",
       "       [6.72769786e-01],\n",
       "       [6.16609909e-01],\n",
       "       [2.37311323e-01],\n",
       "       [1.38869751e-01],\n",
       "       [4.49036311e-01],\n",
       "       [1.30056439e-01],\n",
       "       [2.66943309e-01],\n",
       "       [7.65167389e-01],\n",
       "       [3.65540676e-01],\n",
       "       [2.97239926e-01],\n",
       "       [2.00356694e-01],\n",
       "       [8.01085557e-01],\n",
       "       [8.69357151e-01],\n",
       "       [1.33048981e-01],\n",
       "       [2.06119357e-01],\n",
       "       [2.23613418e-01],\n",
       "       [8.29475612e-01],\n",
       "       [9.90857122e-01],\n",
       "       [8.13166030e-01],\n",
       "       [3.61615695e-01],\n",
       "       [2.85609715e-01],\n",
       "       [2.85477743e-01],\n",
       "       [8.19277197e-01],\n",
       "       [5.47065478e-01],\n",
       "       [9.52480232e-01],\n",
       "       [4.85032334e-01],\n",
       "       [4.14622889e-01],\n",
       "       [4.34147365e-03],\n",
       "       [2.18102797e-01],\n",
       "       [7.01578297e-01],\n",
       "       [1.67213574e-01],\n",
       "       [7.46774941e-01],\n",
       "       [5.17046917e-01],\n",
       "       [2.58524131e-01],\n",
       "       [2.36597584e-01],\n",
       "       [2.47913821e-01],\n",
       "       [8.02830022e-01],\n",
       "       [4.03185000e-01],\n",
       "       [2.06003697e-01],\n",
       "       [9.32935269e-01],\n",
       "       [3.34347448e-01],\n",
       "       [6.51817374e-01],\n",
       "       [7.98933962e-01],\n",
       "       [5.71862697e-01],\n",
       "       [4.29312509e-01],\n",
       "       [7.38836277e-01],\n",
       "       [3.41872933e-02],\n",
       "       [6.52535552e-01],\n",
       "       [7.42627375e-01],\n",
       "       [7.09637266e-01],\n",
       "       [5.11416677e-01],\n",
       "       [7.41545280e-01],\n",
       "       [4.44514815e-01],\n",
       "       [9.91674171e-01],\n",
       "       [9.25453202e-01],\n",
       "       [1.65582163e-01],\n",
       "       [4.38791700e-01],\n",
       "       [6.66743694e-01],\n",
       "       [1.15503941e-01],\n",
       "       [1.64173882e-01],\n",
       "       [8.15942515e-01],\n",
       "       [5.62434806e-01],\n",
       "       [3.32190133e-01],\n",
       "       [1.90839082e-01],\n",
       "       [4.21221175e-01],\n",
       "       [3.17506826e-01],\n",
       "       [4.03714180e-01],\n",
       "       [1.84264046e-01],\n",
       "       [9.61427300e-01],\n",
       "       [2.05366215e-03],\n",
       "       [5.65610570e-01],\n",
       "       [4.08479116e-01],\n",
       "       [9.09707657e-01],\n",
       "       [7.23701951e-02],\n",
       "       [4.10734517e-01],\n",
       "       [5.35910024e-02],\n",
       "       [6.37256590e-01],\n",
       "       [2.61854188e-01],\n",
       "       [3.88452400e-01],\n",
       "       [8.56615203e-01],\n",
       "       [2.22421697e-02],\n",
       "       [8.38170983e-01],\n",
       "       [3.50783966e-01],\n",
       "       [1.01018189e-01],\n",
       "       [5.53679170e-01],\n",
       "       [7.78206890e-01],\n",
       "       [7.39348472e-01],\n",
       "       [4.50958078e-01],\n",
       "       [1.24531134e-01],\n",
       "       [7.73730440e-01],\n",
       "       [1.60711932e-01],\n",
       "       [7.63358163e-01],\n",
       "       [1.47807024e-01],\n",
       "       [5.38506127e-01],\n",
       "       [4.17390427e-01],\n",
       "       [9.22425605e-01],\n",
       "       [7.57735719e-02],\n",
       "       [3.60646644e-01],\n",
       "       [7.11059662e-01],\n",
       "       [8.83038755e-01],\n",
       "       [7.08597448e-01],\n",
       "       [6.66723258e-01],\n",
       "       [4.50610918e-01],\n",
       "       [3.65183484e-02],\n",
       "       [1.79849896e-01],\n",
       "       [4.05920380e-01],\n",
       "       [5.94305366e-01],\n",
       "       [9.32996006e-01],\n",
       "       [2.64726166e-01],\n",
       "       [4.45714750e-01],\n",
       "       [9.06043539e-01],\n",
       "       [6.32148062e-01],\n",
       "       [6.59968357e-01],\n",
       "       [6.34606144e-01],\n",
       "       [2.11996830e-01],\n",
       "       [5.48612201e-01],\n",
       "       [6.70909050e-01],\n",
       "       [3.01405557e-02],\n",
       "       [9.27249813e-01],\n",
       "       [6.91494242e-01],\n",
       "       [5.32047782e-01],\n",
       "       [2.33161652e-01],\n",
       "       [5.36182909e-01],\n",
       "       [9.77002663e-01],\n",
       "       [7.68105065e-02],\n",
       "       [6.39431760e-03],\n",
       "       [5.55031002e-01],\n",
       "       [8.88350766e-01],\n",
       "       [3.14976142e-01],\n",
       "       [5.17715929e-01],\n",
       "       [5.34977080e-01],\n",
       "       [1.43576244e-01],\n",
       "       [2.33730728e-01],\n",
       "       [7.81324232e-01],\n",
       "       [7.54647028e-01],\n",
       "       [5.49509801e-01],\n",
       "       [5.88577130e-01],\n",
       "       [9.79932542e-01],\n",
       "       [7.64930384e-01],\n",
       "       [4.39181069e-01],\n",
       "       [6.94847170e-01],\n",
       "       [9.74327672e-02],\n",
       "       [2.06483566e-01],\n",
       "       [4.18043431e-01],\n",
       "       [8.85385235e-01],\n",
       "       [3.10791234e-01],\n",
       "       [1.41564958e-01],\n",
       "       [4.35616902e-01],\n",
       "       [3.10845440e-01],\n",
       "       [5.25253491e-01],\n",
       "       [5.53384876e-02],\n",
       "       [5.89246860e-01],\n",
       "       [4.33770654e-01],\n",
       "       [6.60464220e-01],\n",
       "       [4.46869318e-01],\n",
       "       [5.46434569e-01],\n",
       "       [3.17913024e-01],\n",
       "       [4.53725754e-01],\n",
       "       [4.59086062e-01],\n",
       "       [6.39166015e-01],\n",
       "       [2.64033606e-01],\n",
       "       [6.35780193e-02],\n",
       "       [6.91375444e-01],\n",
       "       [9.27637836e-01],\n",
       "       [2.58062565e-01],\n",
       "       [8.06778823e-01],\n",
       "       [4.76843470e-01],\n",
       "       [8.63886626e-01],\n",
       "       [8.71704310e-01],\n",
       "       [2.79889841e-01],\n",
       "       [7.70354180e-01],\n",
       "       [6.97507026e-01],\n",
       "       [2.78093304e-01],\n",
       "       [4.28795787e-01],\n",
       "       [1.19724672e-01],\n",
       "       [3.93866838e-01],\n",
       "       [3.22531525e-01],\n",
       "       [8.83662006e-01],\n",
       "       [9.59123541e-01],\n",
       "       [2.54744413e-02],\n",
       "       [6.29187813e-01],\n",
       "       [8.56159861e-01],\n",
       "       [6.41356915e-01],\n",
       "       [7.00969402e-01],\n",
       "       [4.49368724e-01],\n",
       "       [6.42630916e-01],\n",
       "       [6.48338094e-01],\n",
       "       [7.82191497e-01],\n",
       "       [4.04865895e-01],\n",
       "       [4.71882029e-02],\n",
       "       [3.76637869e-01],\n",
       "       [2.97113266e-01],\n",
       "       [7.80250275e-01],\n",
       "       [4.15978814e-01],\n",
       "       [8.08901632e-01],\n",
       "       [9.43895099e-01],\n",
       "       [4.66819734e-01],\n",
       "       [8.14796681e-01],\n",
       "       [4.66782126e-02],\n",
       "       [5.68308101e-02],\n",
       "       [1.57268113e-01],\n",
       "       [8.12477024e-01],\n",
       "       [9.13978373e-01],\n",
       "       [2.95374636e-01],\n",
       "       [2.98238018e-01],\n",
       "       [1.65058981e-01],\n",
       "       [6.19734387e-02],\n",
       "       [9.91196149e-01],\n",
       "       [8.59293083e-01],\n",
       "       [1.03428932e-01],\n",
       "       [2.15718505e-01],\n",
       "       [1.64887480e-01],\n",
       "       [5.44117571e-01],\n",
       "       [7.67195754e-01],\n",
       "       [9.45593394e-01],\n",
       "       [6.63575516e-02],\n",
       "       [9.30928704e-01],\n",
       "       [7.62974705e-01],\n",
       "       [9.82522222e-01],\n",
       "       [2.54468407e-01],\n",
       "       [8.46584567e-01],\n",
       "       [2.29776089e-01],\n",
       "       [9.08339620e-01],\n",
       "       [5.08633754e-01],\n",
       "       [1.94667372e-02],\n",
       "       [5.26940374e-01],\n",
       "       [5.55532167e-02],\n",
       "       [2.73309682e-01],\n",
       "       [6.11203598e-01],\n",
       "       [5.96655678e-01],\n",
       "       [2.90026291e-02],\n",
       "       [3.16720715e-01],\n",
       "       [1.22029118e-01],\n",
       "       [4.29970411e-01],\n",
       "       [7.75204176e-01],\n",
       "       [9.79418619e-01],\n",
       "       [8.32868986e-01],\n",
       "       [8.61202488e-01],\n",
       "       [7.18473543e-01],\n",
       "       [5.99201751e-01],\n",
       "       [7.22382221e-01],\n",
       "       [2.87974214e-01],\n",
       "       [1.04763365e-01],\n",
       "       [1.23021860e-01],\n",
       "       [1.14772549e-01],\n",
       "       [5.55803962e-01],\n",
       "       [9.73809010e-01],\n",
       "       [9.88599279e-01],\n",
       "       [5.02651293e-01],\n",
       "       [1.32847815e-02],\n",
       "       [4.64981563e-01],\n",
       "       [9.66969339e-01],\n",
       "       [1.79316840e-01],\n",
       "       [7.73553705e-01],\n",
       "       [5.94967713e-01],\n",
       "       [1.90037428e-01],\n",
       "       [3.87580461e-01],\n",
       "       [9.06578122e-01],\n",
       "       [9.81283074e-01],\n",
       "       [3.32894740e-01],\n",
       "       [4.75876577e-01],\n",
       "       [8.49507127e-01],\n",
       "       [5.23440422e-02],\n",
       "       [5.32882108e-02],\n",
       "       [3.72997763e-01],\n",
       "       [8.13511348e-01],\n",
       "       [5.88390195e-01],\n",
       "       [2.23805101e-01],\n",
       "       [6.03164308e-01],\n",
       "       [1.66259824e-01],\n",
       "       [4.10428662e-01],\n",
       "       [8.93912933e-01],\n",
       "       [9.07470628e-01],\n",
       "       [1.07152898e-01],\n",
       "       [5.89973473e-01],\n",
       "       [2.29219175e-01],\n",
       "       [2.12510466e-02],\n",
       "       [1.08215084e-01],\n",
       "       [3.38165837e-01],\n",
       "       [4.81910290e-01],\n",
       "       [1.77661518e-01],\n",
       "       [5.07341934e-01],\n",
       "       [6.73462837e-01],\n",
       "       [1.85411052e-01],\n",
       "       [2.98182255e-01],\n",
       "       [7.70059279e-01],\n",
       "       [5.40275834e-01],\n",
       "       [3.19511456e-01],\n",
       "       [3.80166045e-01],\n",
       "       [2.07655260e-01],\n",
       "       [6.48528574e-02],\n",
       "       [7.90252363e-01],\n",
       "       [4.97623420e-01],\n",
       "       [8.91113904e-01],\n",
       "       [7.94522232e-01],\n",
       "       [6.91809054e-02],\n",
       "       [2.66190051e-01],\n",
       "       [3.70903703e-02],\n",
       "       [7.28962755e-02],\n",
       "       [5.68545356e-02],\n",
       "       [5.30945555e-03],\n",
       "       [9.64337625e-01],\n",
       "       [9.47594805e-01],\n",
       "       [4.08010082e-01],\n",
       "       [7.43913604e-01],\n",
       "       [6.66737614e-02],\n",
       "       [7.03155362e-02],\n",
       "       [7.73910396e-01],\n",
       "       [5.60117080e-02],\n",
       "       [7.46608673e-01],\n",
       "       [7.57690856e-01],\n",
       "       [2.33037121e-01],\n",
       "       [4.45623668e-01],\n",
       "       [2.62168638e-01],\n",
       "       [3.56728734e-01],\n",
       "       [8.83096941e-01],\n",
       "       [4.81124243e-01],\n",
       "       [2.88971724e-01],\n",
       "       [2.26872937e-01],\n",
       "       [5.18581762e-01],\n",
       "       [8.12922575e-01],\n",
       "       [4.97264955e-01],\n",
       "       [9.84312772e-01],\n",
       "       [1.44158616e-01],\n",
       "       [2.29572331e-01],\n",
       "       [9.56468399e-01],\n",
       "       [6.33557342e-01],\n",
       "       [3.86804602e-01],\n",
       "       [7.40873852e-01],\n",
       "       [7.77021956e-01],\n",
       "       [5.38666576e-01],\n",
       "       [4.87769053e-01],\n",
       "       [2.57596922e-01],\n",
       "       [6.56661289e-01],\n",
       "       [9.31373753e-01],\n",
       "       [8.91871397e-01],\n",
       "       [1.77516185e-01],\n",
       "       [9.62435172e-01],\n",
       "       [3.26713710e-01],\n",
       "       [3.92959455e-01],\n",
       "       [8.32978246e-01],\n",
       "       [3.81040422e-01],\n",
       "       [3.71184856e-01],\n",
       "       [3.18206271e-01],\n",
       "       [9.96510643e-01],\n",
       "       [1.94828365e-02],\n",
       "       [9.29767126e-01],\n",
       "       [2.51449527e-01],\n",
       "       [8.84219157e-01],\n",
       "       [8.00503220e-01],\n",
       "       [4.36038193e-01],\n",
       "       [2.44171944e-01],\n",
       "       [6.33109346e-01],\n",
       "       [7.88017097e-01],\n",
       "       [4.79944560e-01],\n",
       "       [6.42789682e-01],\n",
       "       [3.55917329e-01],\n",
       "       [1.37958933e-01],\n",
       "       [8.86904234e-01],\n",
       "       [1.94184138e-01],\n",
       "       [6.90708502e-01],\n",
       "       [4.88503141e-01],\n",
       "       [7.55220118e-01],\n",
       "       [1.82686920e-01],\n",
       "       [6.17440202e-01],\n",
       "       [8.26076701e-01],\n",
       "       [4.74211288e-01],\n",
       "       [7.74651344e-01],\n",
       "       [2.57223277e-01],\n",
       "       [6.22631245e-01],\n",
       "       [6.69525551e-01],\n",
       "       [5.06048442e-01],\n",
       "       [8.63456184e-01],\n",
       "       [4.68037127e-01],\n",
       "       [3.86683160e-01],\n",
       "       [9.89456728e-01],\n",
       "       [7.21906147e-01],\n",
       "       [6.94629795e-01],\n",
       "       [7.00711199e-01],\n",
       "       [9.42539273e-01],\n",
       "       [3.40914046e-01],\n",
       "       [5.39686309e-01],\n",
       "       [1.75166979e-01],\n",
       "       [5.04096858e-01],\n",
       "       [1.81106151e-01],\n",
       "       [3.72095684e-02],\n",
       "       [9.35851969e-01],\n",
       "       [3.32385579e-01],\n",
       "       [1.17518824e-01],\n",
       "       [7.03418385e-01],\n",
       "       [8.02303753e-02],\n",
       "       [4.46147943e-01],\n",
       "       [7.92384208e-01],\n",
       "       [5.77515363e-01],\n",
       "       [3.46993372e-01],\n",
       "       [2.54769357e-01],\n",
       "       [6.65736123e-01],\n",
       "       [6.14300932e-01],\n",
       "       [9.09217386e-01],\n",
       "       [1.11680119e-01],\n",
       "       [3.13925988e-01],\n",
       "       [5.22733307e-01],\n",
       "       [6.47718673e-01],\n",
       "       [8.26038606e-02],\n",
       "       [7.62514060e-01],\n",
       "       [6.91971314e-01],\n",
       "       [2.38357847e-01],\n",
       "       [4.95014270e-01],\n",
       "       [8.92343914e-01],\n",
       "       [8.66000423e-01],\n",
       "       [1.58728193e-01],\n",
       "       [1.46622863e-01],\n",
       "       [3.67747440e-01],\n",
       "       [7.85402718e-01],\n",
       "       [2.92864425e-01],\n",
       "       [2.30133759e-01],\n",
       "       [1.00270127e-01],\n",
       "       [1.32474926e-01],\n",
       "       [6.75992656e-01],\n",
       "       [7.30560217e-01],\n",
       "       [6.04344520e-01],\n",
       "       [4.35278924e-01],\n",
       "       [2.59463837e-01],\n",
       "       [2.08408186e-01],\n",
       "       [3.97494598e-02],\n",
       "       [3.31732420e-01],\n",
       "       [2.13145705e-02],\n",
       "       [9.90508623e-01],\n",
       "       [3.21172864e-01],\n",
       "       [2.49160461e-01],\n",
       "       [7.32662013e-01],\n",
       "       [5.62841743e-01],\n",
       "       [6.20579063e-02],\n",
       "       [5.96422359e-02],\n",
       "       [2.15064661e-01],\n",
       "       [3.69006589e-01],\n",
       "       [9.16750010e-01],\n",
       "       [4.08253494e-01],\n",
       "       [3.74708491e-01],\n",
       "       [9.31150681e-01],\n",
       "       [4.76469792e-01],\n",
       "       [5.87329963e-01],\n",
       "       [6.40067203e-01],\n",
       "       [9.50515044e-01],\n",
       "       [2.82525369e-01],\n",
       "       [6.90227645e-02],\n",
       "       [5.60786077e-01],\n",
       "       [2.40600086e-02],\n",
       "       [4.74848142e-01],\n",
       "       [2.96415380e-01],\n",
       "       [5.15649541e-01],\n",
       "       [7.71598425e-01],\n",
       "       [6.19484270e-01],\n",
       "       [7.55566326e-01],\n",
       "       [1.88320988e-01],\n",
       "       [1.20507651e-01],\n",
       "       [7.73754172e-01],\n",
       "       [5.03097572e-01],\n",
       "       [6.81613576e-01],\n",
       "       [5.26540176e-01],\n",
       "       [9.43968987e-03],\n",
       "       [5.07109418e-02],\n",
       "       [8.75537948e-01],\n",
       "       [7.80891278e-01],\n",
       "       [1.49897337e-01],\n",
       "       [3.32712039e-01],\n",
       "       [5.67968677e-01],\n",
       "       [5.07622683e-01],\n",
       "       [6.91374257e-01],\n",
       "       [7.43920213e-01],\n",
       "       [6.91203396e-01],\n",
       "       [7.32184251e-01],\n",
       "       [3.05862111e-01],\n",
       "       [7.43437253e-01],\n",
       "       [5.88644983e-01],\n",
       "       [6.28395457e-01],\n",
       "       [9.53500311e-01],\n",
       "       [3.17095601e-01],\n",
       "       [4.66746328e-01],\n",
       "       [2.10924946e-01],\n",
       "       [8.51684017e-01],\n",
       "       [3.64503776e-01],\n",
       "       [8.65870928e-01],\n",
       "       [8.14616381e-01],\n",
       "       [9.59826739e-01],\n",
       "       [1.49669443e-01],\n",
       "       [3.99803030e-01],\n",
       "       [4.62218105e-01],\n",
       "       [3.71909698e-01],\n",
       "       [1.43017352e-01],\n",
       "       [8.59216143e-01],\n",
       "       [8.81275022e-01],\n",
       "       [7.86083119e-01],\n",
       "       [7.69107013e-01],\n",
       "       [6.18510841e-01],\n",
       "       [8.44252843e-02],\n",
       "       [9.64673679e-01],\n",
       "       [1.01129567e-01],\n",
       "       [2.82887208e-01],\n",
       "       [4.53246268e-01],\n",
       "       [8.98095635e-01],\n",
       "       [9.75723524e-01],\n",
       "       [2.83588824e-01],\n",
       "       [9.48407061e-01],\n",
       "       [7.42928251e-01],\n",
       "       [9.57094669e-01],\n",
       "       [9.44890227e-01],\n",
       "       [1.67747683e-01],\n",
       "       [3.52538391e-01],\n",
       "       [8.52788777e-01],\n",
       "       [8.42209845e-01],\n",
       "       [1.72406776e-01],\n",
       "       [4.69202026e-01],\n",
       "       [3.31268284e-01],\n",
       "       [2.99225604e-03],\n",
       "       [1.60734192e-01],\n",
       "       [3.55594152e-01],\n",
       "       [8.38445643e-01],\n",
       "       [9.41124098e-02],\n",
       "       [8.62975831e-01],\n",
       "       [9.05703654e-01],\n",
       "       [5.43688386e-01],\n",
       "       [4.52705936e-01],\n",
       "       [9.76855598e-01],\n",
       "       [3.57602038e-01],\n",
       "       [2.14671945e-01],\n",
       "       [7.26729530e-01],\n",
       "       [4.14262600e-01],\n",
       "       [7.49765486e-01],\n",
       "       [8.26701606e-01],\n",
       "       [7.83674116e-01],\n",
       "       [6.62949153e-01],\n",
       "       [4.78749290e-01],\n",
       "       [4.07306012e-01],\n",
       "       [8.02973437e-01],\n",
       "       [5.22540365e-01],\n",
       "       [6.14843897e-01],\n",
       "       [8.43791706e-01],\n",
       "       [1.54404957e-02],\n",
       "       [9.73236716e-01],\n",
       "       [3.43546538e-01],\n",
       "       [4.85428805e-02],\n",
       "       [3.54672003e-01],\n",
       "       [2.62701560e-01],\n",
       "       [8.78932747e-02],\n",
       "       [4.56086037e-01],\n",
       "       [5.67681427e-01],\n",
       "       [2.21302927e-01],\n",
       "       [1.64948625e-01],\n",
       "       [4.75241468e-01],\n",
       "       [5.51368589e-01],\n",
       "       [9.94767048e-02],\n",
       "       [7.09289437e-01],\n",
       "       [4.20196221e-01],\n",
       "       [3.42936441e-01],\n",
       "       [2.55172226e-01],\n",
       "       [9.18369092e-01],\n",
       "       [5.17435037e-01],\n",
       "       [9.31853221e-01],\n",
       "       [8.95927898e-01],\n",
       "       [2.78576095e-02],\n",
       "       [9.25621228e-01],\n",
       "       [2.22004246e-01],\n",
       "       [1.43316496e-01],\n",
       "       [1.28143871e-02],\n",
       "       [2.22671061e-01],\n",
       "       [6.13424380e-02],\n",
       "       [2.56161689e-01],\n",
       "       [2.14420805e-01],\n",
       "       [2.22185020e-01],\n",
       "       [6.09444895e-01],\n",
       "       [7.62654717e-01],\n",
       "       [2.03962961e-01],\n",
       "       [3.51641286e-01],\n",
       "       [8.79016798e-01],\n",
       "       [8.36824322e-01],\n",
       "       [4.69177354e-01],\n",
       "       [3.05255662e-01],\n",
       "       [8.02828820e-01],\n",
       "       [3.13330856e-01],\n",
       "       [3.84596965e-01],\n",
       "       [2.42710250e-01],\n",
       "       [7.17607707e-01],\n",
       "       [8.45365336e-01],\n",
       "       [5.48317777e-01],\n",
       "       [9.08411877e-01],\n",
       "       [6.84658166e-01],\n",
       "       [8.27837272e-01],\n",
       "       [1.25476006e-01],\n",
       "       [5.47949670e-01],\n",
       "       [1.27335383e-01],\n",
       "       [3.30362032e-01],\n",
       "       [2.04331033e-01],\n",
       "       [8.01023061e-01],\n",
       "       [1.20366494e-01],\n",
       "       [2.72872750e-01],\n",
       "       [5.09802926e-02],\n",
       "       [3.39093585e-01],\n",
       "       [6.11095160e-01],\n",
       "       [5.53444417e-01],\n",
       "       [7.69102222e-01],\n",
       "       [6.70915444e-02],\n",
       "       [9.60285550e-02],\n",
       "       [1.95582950e-01],\n",
       "       [5.61999261e-01],\n",
       "       [6.03553320e-01],\n",
       "       [3.42496789e-01],\n",
       "       [5.29021911e-02],\n",
       "       [9.67419846e-01],\n",
       "       [3.09711867e-01],\n",
       "       [9.49288639e-01],\n",
       "       [1.06060546e-01],\n",
       "       [2.54085050e-01],\n",
       "       [7.95205173e-01],\n",
       "       [8.88301370e-01],\n",
       "       [3.14155956e-01],\n",
       "       [1.47804062e-02],\n",
       "       [3.22904891e-01],\n",
       "       [8.15915020e-01],\n",
       "       [1.22148353e-01],\n",
       "       [4.81004780e-01],\n",
       "       [8.11295605e-01],\n",
       "       [7.54335298e-01],\n",
       "       [7.24004613e-01],\n",
       "       [2.98976863e-01],\n",
       "       [6.91247941e-04],\n",
       "       [1.41077085e-01],\n",
       "       [1.67452771e-01],\n",
       "       [6.79142967e-01],\n",
       "       [9.21835690e-02],\n",
       "       [9.73574259e-01],\n",
       "       [2.73390331e-01],\n",
       "       [3.05956542e-03],\n",
       "       [8.48416971e-01],\n",
       "       [7.50153134e-01],\n",
       "       [3.39285216e-02],\n",
       "       [4.28846189e-01],\n",
       "       [6.20870508e-01],\n",
       "       [6.90349636e-01],\n",
       "       [3.51213424e-01],\n",
       "       [1.18232194e-01],\n",
       "       [4.32941688e-01],\n",
       "       [9.21940035e-01],\n",
       "       [1.46471676e-01],\n",
       "       [2.88488596e-01],\n",
       "       [5.92722208e-02],\n",
       "       [5.96287234e-02],\n",
       "       [3.38841703e-01],\n",
       "       [7.66294040e-01],\n",
       "       [1.13319687e-01],\n",
       "       [7.29532555e-01],\n",
       "       [3.59899119e-02],\n",
       "       [3.74585258e-01],\n",
       "       [5.45837837e-01],\n",
       "       [8.80204404e-01],\n",
       "       [5.78374064e-01],\n",
       "       [5.29699373e-01],\n",
       "       [5.81296163e-01],\n",
       "       [9.53791473e-01],\n",
       "       [9.59449674e-01],\n",
       "       [4.57544626e-01],\n",
       "       [1.17394274e-01],\n",
       "       [7.68379163e-01],\n",
       "       [3.48598167e-01],\n",
       "       [7.45862115e-01],\n",
       "       [7.33558490e-01],\n",
       "       [6.48484940e-01],\n",
       "       [3.99290938e-01],\n",
       "       [5.80673687e-01],\n",
       "       [6.24586845e-01],\n",
       "       [1.66972498e-01],\n",
       "       [1.87030701e-01],\n",
       "       [6.84148903e-01],\n",
       "       [8.55665502e-01],\n",
       "       [8.83260284e-01],\n",
       "       [1.37004648e-02],\n",
       "       [7.38606632e-01],\n",
       "       [7.63098044e-01],\n",
       "       [5.12059183e-01],\n",
       "       [5.71558238e-01],\n",
       "       [4.35674556e-01],\n",
       "       [3.25087778e-01],\n",
       "       [9.55557176e-01],\n",
       "       [7.25313400e-01],\n",
       "       [5.85139954e-01]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c31710ca-85b1-4c3e-96e0-b2f4df3b87fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'update_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_wgan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_critic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 12\u001b[0m, in \u001b[0;36mtrain_wgan\u001b[1;34m(generator, discriminator, gan, real_data, latent_dim, epochs, batch_size, n_critic)\u001b[0m\n\u001b[0;32m      9\u001b[0m     fake_samples \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mpredict(noise)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Train on real and fake samples with Wasserstein loss\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     d_loss_real \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Real class is -1\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     d_loss_fake \u001b[38;5;241m=\u001b[39m discriminator\u001b[38;5;241m.\u001b[39mtrain_on_batch(fake_samples, np\u001b[38;5;241m.\u001b[39mones((batch_size, \u001b[38;5;241m1\u001b[39m)))   \u001b[38;5;66;03m# Fake class is 1\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Train the generator\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:598\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[1;32m--> 598\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:224\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution), iterator\n\u001b[0;32m    223\u001b[0m     ):\n\u001b[1;32m--> 224\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:110\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.one_step_on_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_step_on_data\u001b[39m(data):\n\u001b[0;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    112\u001b[0m         outputs,\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m    114\u001b[0m         reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    115\u001b[0m     )\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:66\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     58\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n\u001b[0;32m     59\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_loss(\n\u001b[0;32m     60\u001b[0m     x\u001b[38;5;241m=\u001b[39mx,\n\u001b[0;32m     61\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     65\u001b[0m )\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_tracker\u001b[38;5;241m.\u001b[39mupdate_state(\n\u001b[0;32m     67\u001b[0m     loss, sample_weight\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mshape(tree\u001b[38;5;241m.\u001b[39mflatten(x)[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     68\u001b[0m )\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mscale_loss(loss)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'update_state'"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "train_wgan(generator, discriminator, gan, real_data, latent_dim, epochs=10000, batch_size=64, n_critic=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720c26ef-9fac-413c-b146-10a094662886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d4c263-e517-42bc-8ac6-2330c7fbede0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f80b823c-92a1-4382-b9b8-0fd7677d4ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'update_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m real_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Replace with your actual dataset\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Ensure both models are compiled before training\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mtrain_wgan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_critic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 10\u001b[0m, in \u001b[0;36mtrain_wgan\u001b[1;34m(generator, discriminator, gan, real_data, latent_dim, epochs, batch_size, n_critic)\u001b[0m\n\u001b[0;32m      7\u001b[0m     fake_samples \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mpredict(noise)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Train on real and fake samples with Wasserstein loss\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     d_loss_real \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Real class is -1\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     d_loss_fake \u001b[38;5;241m=\u001b[39m discriminator\u001b[38;5;241m.\u001b[39mtrain_on_batch(fake_samples, np\u001b[38;5;241m.\u001b[39mones((batch_size, \u001b[38;5;241m1\u001b[39m)))   \u001b[38;5;66;03m# Fake class is 1\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# You can add gradient penalty here (optional)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Compute and apply gradient penalty if required.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Train generator\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:598\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[1;32m--> 598\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:224\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution), iterator\n\u001b[0;32m    223\u001b[0m     ):\n\u001b[1;32m--> 224\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:110\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.one_step_on_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_step_on_data\u001b[39m(data):\n\u001b[0;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    112\u001b[0m         outputs,\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m    114\u001b[0m         reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    115\u001b[0m     )\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:66\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     58\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n\u001b[0;32m     59\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_loss(\n\u001b[0;32m     60\u001b[0m     x\u001b[38;5;241m=\u001b[39mx,\n\u001b[0;32m     61\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     65\u001b[0m )\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_tracker\u001b[38;5;241m.\u001b[39mupdate_state(\n\u001b[0;32m     67\u001b[0m     loss, sample_weight\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mshape(tree\u001b[38;5;241m.\u001b[39mflatten(x)[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     68\u001b[0m )\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mscale_loss(loss)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'update_state'"
     ]
    }
   ],
   "source": [
    "def train_wgan(generator, discriminator, gan, real_data, latent_dim, epochs, batch_size, n_critic):\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(n_critic):\n",
    "            # Train discriminator\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "            real_samples = real_data[np.random.randint(0, real_data.shape[0], batch_size)]\n",
    "            fake_samples = generator.predict(noise)\n",
    "            \n",
    "            # Train on real and fake samples with Wasserstein loss\n",
    "            d_loss_real = discriminator.train_on_batch(real_samples, -np.ones((batch_size, 1)))  # Real class is -1\n",
    "            d_loss_fake = discriminator.train_on_batch(fake_samples, np.ones((batch_size, 1)))   # Fake class is 1\n",
    "            \n",
    "            # You can add gradient penalty here (optional)\n",
    "            # Compute and apply gradient penalty if required.\n",
    "        \n",
    "        # Train generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        g_loss = gan.train_on_batch(noise, -np.ones((batch_size, 1)))  # Generator tries to fool the discriminator (label: -1)\n",
    "\n",
    "        # Print the progress\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs} - D Loss: {d_loss_real + d_loss_fake:.4f}, G Loss: {g_loss:.4f}\")\n",
    "\n",
    "# Assuming the generator and discriminator are already defined\n",
    "latent_dim = 10\n",
    "real_data = np.random.rand(1000, 1)  # Replace with your actual dataset\n",
    "\n",
    "# Ensure both models are compiled before training\n",
    "train_wgan(generator, discriminator, gan, real_data, latent_dim, epochs=10000, batch_size=64, n_critic=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a2d087-a0d0-4229-9c06-c4d10637068b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343cc8bc-7021-40c6-9fbe-ec21e54c54c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61f7e238-05e0-45a6-997a-847bbca360c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Optimizers\n",
    "optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "# Build the models\n",
    "latent_dim = 10  # Latent dimension for noise input\n",
    "data_dim = 1     # Dimension of your real data\n",
    "\n",
    "generator = build_generator(latent_dim, data_dim)\n",
    "discriminator = build_discriminator(data_dim)\n",
    "\n",
    "# Compile discriminator with Wasserstein loss\n",
    "discriminator.compile(optimizer=optimizer, loss=wasserstein_loss)\n",
    "\n",
    "# Make the discriminator non-trainable when training the GAN model\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Build the GAN (generator + discriminator)\n",
    "gan_input = layers.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = models.Model(gan_input, gan_output)\n",
    "\n",
    "# Compile the GAN model with generator optimizer\n",
    "gan.compile(optimizer=optimizer, loss=wasserstein_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c937e-0fac-4afe-a2bc-08217dec4f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11aff525-94c0-4093-94c1-73860a5903e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def compute_gradient_penalty(real_samples, fake_samples):\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = K.random_uniform(shape=[real_samples.shape[0], 1], minval=0., maxval=1.)\n",
    "    interpolates = alpha * real_samples + (1 - alpha) * fake_samples\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolates)\n",
    "        pred = discriminator(interpolates)\n",
    "    \n",
    "    # Compute gradients of predictions with respect to the interpolates\n",
    "    gradients = tape.gradient(pred, interpolates)\n",
    "    norm = K.sqrt(K.sum(K.square(gradients), axis=1))\n",
    "    \n",
    "    # Compute gradient penalty\n",
    "    penalty = K.mean(K.square(norm - 1.0))\n",
    "    return penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26be8f78-396a-4778-89fa-bde60a1d4b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'update_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m latent_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     43\u001b[0m real_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Replace with your actual dataset\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[43mtrain_wgan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_critic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 18\u001b[0m, in \u001b[0;36mtrain_wgan\u001b[1;34m(generator, discriminator, gan, real_data, latent_dim, epochs, batch_size, n_critic)\u001b[0m\n\u001b[0;32m     15\u001b[0m     fake_samples \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mpredict(noise)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Train on real and fake samples with Wasserstein loss\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     d_loss_real \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Real class is -1\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     d_loss_fake \u001b[38;5;241m=\u001b[39m discriminator\u001b[38;5;241m.\u001b[39mtrain_on_batch(fake_samples, np\u001b[38;5;241m.\u001b[39mones((batch_size, \u001b[38;5;241m1\u001b[39m)))   \u001b[38;5;66;03m# Fake class is 1\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Compute gradient penalty here (if needed)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# For simplicity, you can skip this part in a basic WGAN implementation.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Train generator\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:598\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[1;32m--> 598\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:224\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution), iterator\n\u001b[0;32m    223\u001b[0m     ):\n\u001b[1;32m--> 224\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:110\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.one_step_on_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_step_on_data\u001b[39m(data):\n\u001b[0;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    112\u001b[0m         outputs,\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m    114\u001b[0m         reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    115\u001b[0m     )\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:66\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     58\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n\u001b[0;32m     59\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_loss(\n\u001b[0;32m     60\u001b[0m     x\u001b[38;5;241m=\u001b[39mx,\n\u001b[0;32m     61\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     65\u001b[0m )\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_tracker\u001b[38;5;241m.\u001b[39mupdate_state(\n\u001b[0;32m     67\u001b[0m     loss, sample_weight\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mshape(tree\u001b[38;5;241m.\u001b[39mflatten(x)[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     68\u001b[0m )\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mscale_loss(loss)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'update_state'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "# Wasserstein loss\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "# Train the WGAN\n",
    "def train_wgan(generator, discriminator, gan, real_data, latent_dim, epochs, batch_size, n_critic):\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(n_critic):\n",
    "            # Train discriminator\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "            real_samples = real_data[np.random.randint(0, real_data.shape[0], batch_size)]\n",
    "            fake_samples = generator.predict(noise)\n",
    "            \n",
    "            # Train on real and fake samples with Wasserstein loss\n",
    "            d_loss_real = discriminator.train_on_batch(real_samples, -np.ones((batch_size, 1)))  # Real class is -1\n",
    "            d_loss_fake = discriminator.train_on_batch(fake_samples, np.ones((batch_size, 1)))   # Fake class is 1\n",
    "            \n",
    "            # Compute gradient penalty here (if needed)\n",
    "            # For simplicity, you can skip this part in a basic WGAN implementation.\n",
    "        \n",
    "        # Train generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        g_loss = gan.train_on_batch(noise, -np.ones((batch_size, 1)))  # Generator tries to fool the discriminator (label: -1)\n",
    "\n",
    "        # Print the progress\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs} - D Loss: {d_loss_real + d_loss_fake:.4f}, G Loss: {g_loss:.4f}\")\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "# Compile the discriminator with Wasserstein loss\n",
    "discriminator.compile(loss=wasserstein_loss, optimizer=optimizer)\n",
    "\n",
    "# Compile the GAN (stacked generator and discriminator) with Wasserstein loss\n",
    "gan.compile(loss=wasserstein_loss, optimizer=optimizer)\n",
    "\n",
    "# Create and train the models (assuming you have defined the generator and discriminator already)\n",
    "latent_dim = 10\n",
    "real_data = np.random.rand(1000, 1)  # Replace with your actual dataset\n",
    "train_wgan(generator, discriminator, gan, real_data, latent_dim, epochs=10000, batch_size=64, n_critic=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "807237da-84a9-42a1-bb7c-7c71acce3580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'update_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m real_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Replace with your actual dataset\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtrain_wgan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_critic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 19\u001b[0m, in \u001b[0;36mtrain_wgan\u001b[1;34m(generator, discriminator, gan, real_data, latent_dim, epochs, batch_size, n_critic)\u001b[0m\n\u001b[0;32m     16\u001b[0m fake_samples \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mpredict(noise)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Train the discriminator on real and fake samples\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m d_loss_real \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Real class is -1\u001b[39;00m\n\u001b[0;32m     20\u001b[0m d_loss_fake \u001b[38;5;241m=\u001b[39m discriminator\u001b[38;5;241m.\u001b[39mtrain_on_batch(fake_samples, np\u001b[38;5;241m.\u001b[39mones((batch_size, \u001b[38;5;241m1\u001b[39m)))   \u001b[38;5;66;03m# Fake class is 1\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Compute gradient penalty\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:598\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[1;32m--> 598\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:224\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution), iterator\n\u001b[0;32m    223\u001b[0m     ):\n\u001b[1;32m--> 224\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:110\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.one_step_on_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_step_on_data\u001b[39m(data):\n\u001b[0;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    112\u001b[0m         outputs,\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m    114\u001b[0m         reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    115\u001b[0m     )\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Civil\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:66\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     58\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n\u001b[0;32m     59\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_loss(\n\u001b[0;32m     60\u001b[0m     x\u001b[38;5;241m=\u001b[39mx,\n\u001b[0;32m     61\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     65\u001b[0m )\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_tracker\u001b[38;5;241m.\u001b[39mupdate_state(\n\u001b[0;32m     67\u001b[0m     loss, sample_weight\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mshape(tree\u001b[38;5;241m.\u001b[39mflatten(x)[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     68\u001b[0m )\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mscale_loss(loss)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'update_state'"
     ]
    }
   ],
   "source": [
    "# Real data (example for regression task)\n",
    "real_data = np.random.rand(1000, 1)  # Replace with your actual dataset\n",
    "\n",
    "# Train the model\n",
    "train_wgan(generator, discriminator, gan, real_data, latent_dim=10, epochs=10000, batch_size=64, n_critic=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4eca3f9-6420-4261-a243-09d51a03739a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'latent_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Generate new samples (for regression)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m10\u001b[39m, \u001b[43mlatent_dim\u001b[49m))  \u001b[38;5;66;03m# Generate 10 samples\u001b[39;00m\n\u001b[0;32m      3\u001b[0m generated_data \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mpredict(noise)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(generated_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'latent_dim' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate new samples (for regression)\n",
    "noise = np.random.normal(0, 1, (10, latent_dim))  # Generate 10 samples\n",
    "generated_data = generator.predict(noise)\n",
    "print(generated_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e806ee-c0a4-4583-b17d-727df52b2885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
